{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_applications==1.0.6\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 66.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras==2.2.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 95.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras_applications==1.0.6)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.9MB 99.6MB/s eta 0:00:01�█████▎                    | 1.0MB 79.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.9.1 (from keras_applications==1.0.6)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.4MB 100.3MB/s ta 0:00:01      | 2.6MB 61.6MB/s eta 0:00:01��████▎                    | 7.2MB 89.6MB/s eta 0:00:01�██              | 11.5MB 89.9MB/s eta 0:00:01███████████████▊       | 15.7MB 87.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras==2.2.4)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 58.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14 (from keras==2.2.4)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.2MB 66.1MB/s ta 0:00:011.1MB 89.0MB/s eta 0:00:01s eta 0:00:01           | 11.0MB 91.2MB/s eta 0:00:01   | 14.8MB 90.8MB/s eta 0:00:01███████████████████▊       | 19.5MB 91.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml (from keras==2.2.4)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
      "\u001b[K    100% |████████████████████████████████| 266kB 95.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.9.0 (from keras==2.2.4)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/b8/f2/93/0b52ea3f4f41d99c6ac25eee588b7ddb3d59a37e1d5457c690\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: numpy, six, h5py, keras-applications, keras-preprocessing, scipy, pyyaml, keras\n",
      "  Found existing installation: numpy 1.16.2\n",
      "    Uninstalling numpy-1.16.2:\n",
      "      Successfully uninstalled numpy-1.16.2\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\n",
      "  Found existing installation: Keras-Applications 1.0.2\n",
      "    Uninstalling Keras-Applications-1.0.2:\n",
      "      Successfully uninstalled Keras-Applications-1.0.2\n",
      "  Found existing installation: Keras-Preprocessing 1.0.1\n",
      "    Uninstalling Keras-Preprocessing-1.0.1:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.0.1\n",
      "  Found existing installation: scipy 1.0.0\n",
      "    Uninstalling scipy-1.0.0:\n",
      "      Successfully uninstalled scipy-1.0.0\n",
      "  Found existing installation: PyYAML 3.12\n",
      "    Uninstalling PyYAML-3.12:\n",
      "      Successfully uninstalled PyYAML-3.12\n",
      "  Found existing installation: Keras 2.2.0\n",
      "    Uninstalling Keras-2.2.0:\n",
      "      Successfully uninstalled Keras-2.2.0\n",
      "Successfully installed h5py-2.10.0 keras-2.2.4 keras-applications-1.0.6 keras-preprocessing-1.1.0 numpy-1.17.2 pyyaml-5.1.2 scipy-1.3.1 six-1.12.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras_applications==1.0.6 keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file modelarts-labs/end2end/image_recognition/dog_and_cat_25000.tar.gz from OBS to local ./dog_and_cat_25000.tar.gz\n",
      "rm: cannot remove 'xf': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists('./data') == False:\n",
    "    from modelarts.session import Session\n",
    "    session = Session()\n",
    "    \n",
    "    if session.region_name == 'cn-north-1':\n",
    "        bucket_path = 'modelarts-labs/end2end/image_recognition/dog_and_cat_25000.tar.gz'\n",
    "    elif session.region_name == 'cn-north-4':\n",
    "        bucket_path = 'modelarts-labs-bj4/end2end/image_recognition/dog_and_cat_25000.tar.gz'\n",
    "    else:\n",
    "        print('请更换到北京1或北京4')\n",
    "    \n",
    "    session.download_data(bucket_path=bucket_path,\n",
    "                         path = './dog_and_cat_25000.tar.gz')\n",
    "    !tar xf ./dog_and_cat_25000.tar.gz\n",
    "    !rm xf ./dog_and_cat_25000.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "def load_data():\n",
    "    dirname = './data'\n",
    "    path = './data'\n",
    "    num_train = 25000\n",
    "    x_train = np.empty((num_train,224,224,3),dtype='uint8')\n",
    "    y_train = np.empty((num_train,1),dtype='uint8') ##生成指定形状的数组\n",
    "    index = 0\n",
    "    for file in os.listdir('./data'):\n",
    "        image = Image.open(os.path.join(dirname,file)).resize((224,224))\n",
    "        image = np.array(image)\n",
    "        x_train[index,:,:,:] = image\n",
    "        if 'cat' in file:\n",
    "            y_train[index,0] = 1\n",
    "        elif 'dog' in file:\n",
    "            y_train[index,0] = 0\n",
    "            \n",
    "        index += 1\n",
    "    return (x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 224, 224, 3)\n",
      "(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "def process_data(x_train,y_train):\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_train = x_train / 255.0\n",
    "    n_class = 2\n",
    "    y_train = np_utils.to_categorical(y_train,n_class)\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train = process_data(x_train,y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "def bulid_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(2,activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input,output=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(weights=None,include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model = bulid_model(base_model)\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "               optimizer=opt,\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def schd(epoch):\n",
    "    decay = 1e-6\n",
    "    lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr,lr-decay/(epoch+1))\n",
    "    print('lr changed to {}'.format(lr))\n",
    "    print('lll:',K.get_value(model.optimizer.lr))\n",
    "    return K.get_value(model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler,EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_acc',min_delta=0.001,patience=5,verbose=1,mode='auto')\n",
    "cp = ModelCheckpoint(filepath='./model/ckp_vgg16_dog_and_cat.h5',monitor='val_acc',\n",
    "                    verbose=1,save_best_only=True,mode='auto',period=1)\n",
    "lr = ReduceLROnPlateau(monitor='val_acc',factor=0.1,patience=5,verbose=1,mode='auto',min_lr=0)\n",
    "ls = LearningRateScheduler(schedule=schd,verbose=1)\n",
    "callback = [es,cp,lr,ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18750 samples, validate on 6250 samples\n",
      "Epoch 1/5\n",
      "lr changed to 9.999999747378752e-05\n",
      "lll: 9.9e-05\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 9.9e-05.\n",
      "18750/18750 [==============================] - 178s 10ms/step - loss: 0.6751 - acc: 0.5868 - val_loss: 0.6210 - val_acc: 0.6610\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66096, saving model to ./model/ckp_vgg16_dog_and_cat.h5\n",
      "Epoch 2/5\n",
      "lr changed to 9.899999713525176e-05\n",
      "lll: 9.85e-05\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 9.85e-05.\n",
      "18750/18750 [==============================] - 161s 9ms/step - loss: 0.6025 - acc: 0.6850 - val_loss: 0.5465 - val_acc: 0.7371\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66096 to 0.73712, saving model to ./model/ckp_vgg16_dog_and_cat.h5\n",
      "Epoch 3/5\n",
      "lr changed to 9.850000060396269e-05\n",
      "lll: 9.816667e-05\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 9.816667e-05.\n",
      "18750/18750 [==============================] - 161s 9ms/step - loss: 0.5398 - acc: 0.7395 - val_loss: 0.5257 - val_acc: 0.7494\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73712 to 0.74944, saving model to ./model/ckp_vgg16_dog_and_cat.h5\n",
      "Epoch 4/5\n",
      "lr changed to 9.81666671577841e-05\n",
      "lll: 9.7916665e-05\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 9.7916665e-05.\n",
      "18750/18750 [==============================] - 161s 9ms/step - loss: 0.4809 - acc: 0.7810 - val_loss: 0.4723 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.74944 to 0.78864, saving model to ./model/ckp_vgg16_dog_and_cat.h5\n",
      "Epoch 5/5\n",
      "lr changed to 9.791666525416076e-05\n",
      "lll: 9.7716664e-05\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 9.7716664e-05.\n",
      "18750/18750 [==============================] - 161s 9ms/step - loss: 0.4272 - acc: 0.8134 - val_loss: 0.3847 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.78864 to 0.83440, saving model to ./model/ckp_vgg16_dog_and_cat.h5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train,\n",
    "                     y = y_train,\n",
    "                     batch_size=16,\n",
    "                     epochs=5,\n",
    "                     verbose=1,\n",
    "                     callbacks=callback,\n",
    "                     validation_split=0.25,\n",
    "                     shuffle=True,\n",
    "                     initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.13.1",
   "language": "python",
   "name": "tensorflow-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
